{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.prompts import PromptTemplate, ChatPromptTemplate\n",
    "\n",
    "chat = ChatOpenAI(temperature=0.1) \n",
    "\n",
    "template = PromptTemplate.from_template(\n",
    "    \"{country_a}와 {country_b}사이의 거리는 얼마나 되니?\"\n",
    ")\n",
    "\n",
    "prompt = template.format(country_a=\"멕시코\", country_b=\"한국\")\n",
    "\n",
    "chat.predict(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "template = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"당신은 전문 지리학자이다. 오직 {language}로만 대화를 한다\"),\n",
    "    (\"ai\", \"안녕, {name}\"), \n",
    "    (\"human\", \"{country_a}와 {country_b}사이의 거리는 얼마나 되니? 그리고 당신의 이름은 무엇이니?\")  \n",
    "])\n",
    "\n",
    "prompt = template.format_messages(\n",
    "    language=\"korean\", \n",
    "    name=\"조현일\", \n",
    "    country_a=\"한국\", \n",
    "    country_b=\"일본\"\n",
    ")\n",
    "\n",
    "chat.predict_messages(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.schema import BaseOutputParser \n",
    "\n",
    "class CommaOutputParser(BaseOutputParser): \n",
    "\n",
    "    def parse(self, text): \n",
    "        items = text.strip().split(\",\")\n",
    "        return list(map(str.strip, items))\n",
    "    \n",
    "\n",
    "p = CommaOutputParser()\n",
    "p.parse(\"Hello, how,are,you\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "template = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"당신은 list생성기계입니다. 입력받은 질문들은 모두 콤마로 구분된 list로 답해야 한다 최대 {max_items}로 답해야 한다.\"), \n",
    "    (\"human\", \"{question}\")\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain_one = template | chat | CommaOutputParser() \n",
    "\n",
    "\n",
    "chain.invoke({\n",
    "    \"max_items\": 5, \n",
    "    \"question\" : \"세계적인 자동차는 무엇인가?\"\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.prompts.few_shot import FewShotChatMessagePromptTemplate\n",
    "from langchain.callbacks import StreamingStdOutCallbackHandler \n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "\n",
    "chat = ChatOpenAI(\n",
    "    temperature=0.1, \n",
    "    streaming=True, \n",
    "    callbacks=[\n",
    "        StreamingStdOutCallbackHandler()\n",
    "    ]\n",
    ")\n",
    "\n",
    "examples = [\n",
    "    {\n",
    "        \"question\": \"France\",\n",
    "        \"answer\": \"\"\"\n",
    "        Here is what I know:\n",
    "        Capital: Paris\n",
    "        Language: French\n",
    "        Food: Wine and Cheese\n",
    "        Currency: Euro\n",
    "        \"\"\",\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"Italy\",\n",
    "        \"answer\": \"\"\"\n",
    "        I know this:\n",
    "        Capital: Rome\n",
    "        Language: Italian\n",
    "        Food: Pizza and Pasta\n",
    "        Currency: Euro\n",
    "        \"\"\",\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"Greece\",\n",
    "        \"answer\": \"\"\"\n",
    "        I know this:\n",
    "        Capital: Athens\n",
    "        Language: Greek\n",
    "        Food: Souvlaki and Feta Cheese\n",
    "        Currency: Euro\n",
    "        \"\"\",\n",
    "    },\n",
    "]\n",
    "\n",
    "\n",
    "example_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"human\", \"What do you know about {question}?\"), \n",
    "    (\"ai\", \"{answer}\")\n",
    "])\n",
    "\n",
    "example_prompt = FewShotChatMessagePromptTemplate(\n",
    "    example_prompt=example_prompt, \n",
    "    examples=examples\n",
    ")\n",
    "\n",
    "final_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"You are a geography expert\"), \n",
    "    example_prompt, \n",
    "    (\"human\", \"What do you know about {country}?\")\n",
    "])\n",
    "\n",
    "chain = final_prompt | chat \n",
    "\n",
    "chain.invoke({\n",
    "    \"country\": \"Korea\", \n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import ChatOpenAI \n",
    "from langchain.prompts.few_shot import FewShotPromptTemplate \n",
    "from langchain.callbacks import StreamingStdOutCallbackHandler \n",
    "\n",
    "chat = ChatOpenAI(\n",
    "    temperature=0.1, \n",
    "    streaming=True, \n",
    "    callbacks=[\n",
    "        StreamingStdOutCallbackHandler()\n",
    "    ]\n",
    ")\n",
    "\n",
    "examples = [\n",
    "    {\n",
    "        \"question\": \"France\",\n",
    "        \"answer\": \"\"\"\n",
    "        Here is what I know:\n",
    "        Capital: Paris\n",
    "        Language: French\n",
    "        Food: Wine and Cheese\n",
    "        Currency: Euro\n",
    "        \"\"\",\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"Italy\",\n",
    "        \"answer\": \"\"\"\n",
    "        I know this:\n",
    "        Capital: Rome\n",
    "        Language: Italian\n",
    "        Food: Pizza and Pasta\n",
    "        Currency: Euro\n",
    "        \"\"\",\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"Greece\",\n",
    "        \"answer\": \"\"\"\n",
    "        I know this:\n",
    "        Capital: Athens\n",
    "        Language: Greek\n",
    "        Food: Souvlaki and Feta Cheese\n",
    "        Currency: Euro\n",
    "        \"\"\",\n",
    "    },\n",
    "]\n",
    "\n",
    "\n",
    "example_template = \"\"\"\n",
    "    Human: {question}, \n",
    "    AI: {answer}\n",
    "\"\"\"\n",
    "\n",
    "example_prompt = PromptTemplate.from_template(example_template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessageChunk(content='\\nI\\'m sorry, I don\\'t have information on \"한국.\" Can you provide more context or specify which country or region you are referring to?')"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.prompts.few_shot import FewShotChatMessagePromptTemplate\n",
    "from langchain.callbacks import StreamingStdOutCallbackHandler\n",
    "from langchain.prompts import ChatMessagePromptTemplate, ChatPromptTemplate\n",
    "from langchain.prompts.example_selector import LengthBasedExampleSelector\n",
    "\n",
    "chat = ChatOpenAI(\n",
    "    temperature=0.1,\n",
    "    streaming=True,\n",
    "    callbacks=[\n",
    "        StreamingStdOutCallbackHandler(),\n",
    "    ],\n",
    ")\n",
    "\n",
    "\n",
    "examples = [\n",
    "    {\n",
    "        \"country\": \"France\",\n",
    "        \"answer\": \"\"\"\n",
    "        Here is what I know:\n",
    "        Capital: Paris\n",
    "        Language: French\n",
    "        Food: Wine and Cheese\n",
    "        Currency: Euro\n",
    "        \"\"\",\n",
    "    },\n",
    "    {\n",
    "        \"country\": \"Italy\",\n",
    "        \"answer\": \"\"\"\n",
    "        I know this:\n",
    "        Capital: Rome\n",
    "        Language: Italian\n",
    "        Food: Pizza and Pasta\n",
    "        Currency: Euro\n",
    "        \"\"\",\n",
    "    },\n",
    "    {\n",
    "        \"country\": \"Greece\",\n",
    "        \"answer\": \"\"\"\n",
    "        I know this:\n",
    "        Capital: Athens\n",
    "        Language: Greek\n",
    "        Food: Souvlaki and Feta Cheese\n",
    "        Currency: Euro\n",
    "        \"\"\",\n",
    "    },\n",
    "]\n",
    "\n",
    "\n",
    "example_prompt = ChatPromptTemplate.from_messages([\n",
    "  (\"human\", \"What do you know about {country}?\"), \n",
    "  (\"ai\", \"{answer}\")\n",
    "])\n",
    "\n",
    "example_prompt = FewShotChatMessagePromptTemplate(\n",
    "  example_prompt=example_prompt, \n",
    "  examples=examples, \n",
    ")\n",
    "\n",
    "final_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", \"You are a geography expert, you give short answers.\"),\n",
    "        example_prompt,\n",
    "        (\"human\", \"What do you know about {country}?\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "chain = final_prompt | chat\n",
    "\n",
    "chain.invoke({\"country\": \"한국\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValidationError",
     "evalue": "3 validation errors for FewShotChatMessagePromptTemplate\nexample_prompt\n  Can't instantiate abstract class BaseMessagePromptTemplate with abstract methods format_messages, input_variables (type=type_error)\nexample_prompt\n  Can't instantiate abstract class BaseChatPromptTemplate with abstract method format_messages (type=type_error)\nsuffix\n  extra fields not permitted (type=value_error.extra)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValidationError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[30], line 58\u001b[0m\n\u001b[1;32m     50\u001b[0m example_prompt \u001b[38;5;241m=\u001b[39m PromptTemplate\u001b[38;5;241m.\u001b[39mfrom_template(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mHuman: \u001b[39m\u001b[38;5;132;01m{question}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mAI: \u001b[39m\u001b[38;5;132;01m{answer}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     52\u001b[0m example_selector \u001b[38;5;241m=\u001b[39m LengthBasedExampleSelector(\n\u001b[1;32m     53\u001b[0m   examples\u001b[38;5;241m=\u001b[39mexamples, \n\u001b[1;32m     54\u001b[0m   example_prompt\u001b[38;5;241m=\u001b[39mexample_prompt, \n\u001b[1;32m     55\u001b[0m   max_length\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m\n\u001b[1;32m     56\u001b[0m )\n\u001b[0;32m---> 58\u001b[0m prompt \u001b[38;5;241m=\u001b[39m \u001b[43mFewShotChatMessagePromptTemplate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     59\u001b[0m \u001b[43m  \u001b[49m\u001b[43mexample_prompt\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mexample_prompt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     60\u001b[0m \u001b[43m  \u001b[49m\u001b[43mexample_selector\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexample_selector\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     61\u001b[0m \u001b[43m  \u001b[49m\u001b[43msuffix\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mHuman: What do you know about \u001b[39;49m\u001b[38;5;132;43;01m{country}\u001b[39;49;00m\u001b[38;5;124;43m?\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     62\u001b[0m \u001b[43m  \u001b[49m\u001b[43minput_variables\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcountry\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[1;32m     63\u001b[0m \n\u001b[1;32m     64\u001b[0m \u001b[43m)\u001b[49m\n\u001b[1;32m     66\u001b[0m prompt\u001b[38;5;241m.\u001b[39mformat(country\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBrazil\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/Documents/code/python/nomad/env/lib/python3.11/site-packages/langchain/load/serializable.py:97\u001b[0m, in \u001b[0;36mSerializable.__init__\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m     96\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m---> 97\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     98\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lc_kwargs \u001b[38;5;241m=\u001b[39m kwargs\n",
      "File \u001b[0;32m~/Documents/code/python/nomad/env/lib/python3.11/site-packages/pydantic/main.py:341\u001b[0m, in \u001b[0;36mpydantic.main.BaseModel.__init__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mValidationError\u001b[0m: 3 validation errors for FewShotChatMessagePromptTemplate\nexample_prompt\n  Can't instantiate abstract class BaseMessagePromptTemplate with abstract methods format_messages, input_variables (type=type_error)\nexample_prompt\n  Can't instantiate abstract class BaseChatPromptTemplate with abstract method format_messages (type=type_error)\nsuffix\n  extra fields not permitted (type=value_error.extra)"
     ]
    }
   ],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.prompts.few_shot import FewShotChatMessagePromptTemplate\n",
    "from langchain.callbacks import StreamingStdOutCallbackHandler\n",
    "from langchain.prompts import ChatMessagePromptTemplate, ChatPromptTemplate\n",
    "from langchain.prompts.example_selector import LengthBasedExampleSelector\n",
    "\n",
    "chat = ChatOpenAI(\n",
    "    temperature=0.1,\n",
    "    streaming=True,\n",
    "    callbacks=[\n",
    "        StreamingStdOutCallbackHandler(),\n",
    "    ],\n",
    ")\n",
    "\n",
    "\n",
    "examples = [\n",
    "    {\n",
    "        \"question\": \"What do you know about France?\",\n",
    "        \"answer\": \"\"\"\n",
    "        Here is what I know:\n",
    "        Capital: Paris\n",
    "        Language: French\n",
    "        Food: Wine and Cheese\n",
    "        Currency: Euro\n",
    "        \"\"\",\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"What do you know about Italy?\",\n",
    "        \"answer\": \"\"\"\n",
    "        I know this:\n",
    "        Capital: Rome\n",
    "        Language: Italian\n",
    "        Food: Pizza and Pasta\n",
    "        Currency: Euro\n",
    "        \"\"\",\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"What do you know about Greece?\",\n",
    "        \"answer\": \"\"\"\n",
    "        I know this:\n",
    "        Capital: Athens\n",
    "        Language: Greek\n",
    "        Food: Souvlaki and Feta Cheese\n",
    "        Currency: Euro\n",
    "        \"\"\",\n",
    "    },\n",
    "]\n",
    "\n",
    "\n",
    "example_prompt = PromptTemplate.from_template(\"Human: {question}\\nAI: {answer}\")\n",
    "\n",
    "example_selector = LengthBasedExampleSelector(\n",
    "  examples=examples, \n",
    "  example_prompt=example_prompt, \n",
    "  max_length=0\n",
    ")\n",
    "\n",
    "prompt = FewShotChatMessagePromptTemplate(\n",
    "  example_prompt = example_prompt, \n",
    "  example_selector=example_selector,\n",
    "  suffix=\"Human: What do you know about {country}?\", \n",
    "  input_variables=[\"country\"]\n",
    "\n",
    ")\n",
    "\n",
    "prompt.format(country=\"Brazil\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'FewShotPromptTemplate' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[29], line 72\u001b[0m\n\u001b[1;32m     66\u001b[0m example_prompt \u001b[38;5;241m=\u001b[39m PromptTemplate\u001b[38;5;241m.\u001b[39mfrom_template(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mHuman: \u001b[39m\u001b[38;5;132;01m{question}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mAI: \u001b[39m\u001b[38;5;132;01m{answer}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     68\u001b[0m example_selector \u001b[38;5;241m=\u001b[39m RandomExampleSelector(\n\u001b[1;32m     69\u001b[0m   examples\u001b[38;5;241m=\u001b[39mexamples, \n\u001b[1;32m     70\u001b[0m )\n\u001b[0;32m---> 72\u001b[0m prompt \u001b[38;5;241m=\u001b[39m \u001b[43mFewShotPromptTemplate\u001b[49m(\n\u001b[1;32m     73\u001b[0m   example_prompt \u001b[38;5;241m=\u001b[39m example_prompt, \n\u001b[1;32m     74\u001b[0m   example_selector\u001b[38;5;241m=\u001b[39mexample_selector,\n\u001b[1;32m     75\u001b[0m   suffix\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mHuman: What do you know about \u001b[39m\u001b[38;5;132;01m{country}\u001b[39;00m\u001b[38;5;124m?\u001b[39m\u001b[38;5;124m\"\u001b[39m, \n\u001b[1;32m     76\u001b[0m   input_variables\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcountry\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m     77\u001b[0m \n\u001b[1;32m     78\u001b[0m )\n\u001b[1;32m     80\u001b[0m prompt\u001b[38;5;241m.\u001b[39mformat(country\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBrazil\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'FewShotPromptTemplate' is not defined"
     ]
    }
   ],
   "source": [
    "from typing import Any, Dict\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.prompts.few_shot import FewShotChatMessagePromptTemplate\n",
    "from langchain.callbacks import StreamingStdOutCallbackHandler\n",
    "from langchain.prompts import ChatMessagePromptTemplate, ChatPromptTemplate\n",
    "from langchain.prompts.example_selector import LengthBasedExampleSelector\n",
    "from langchain.prompts.example_selector.base import BaseExampleSelector \n",
    "\n",
    "\n",
    "\n",
    "chat = ChatOpenAI(\n",
    "    temperature=0.1,\n",
    "    streaming=True,\n",
    "    callbacks=[\n",
    "        StreamingStdOutCallbackHandler(),\n",
    "    ],\n",
    ")\n",
    "\n",
    "\n",
    "examples = [\n",
    "    {\n",
    "        \"question\": \"What do you know about France?\",\n",
    "        \"answer\": \"\"\"\n",
    "        Here is what I know:\n",
    "        Capital: Paris\n",
    "        Language: French\n",
    "        Food: Wine and Cheese\n",
    "        Currency: Euro\n",
    "        \"\"\",\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"What do you know about Italy?\",\n",
    "        \"answer\": \"\"\"\n",
    "        I know this:\n",
    "        Capital: Rome\n",
    "        Language: Italian\n",
    "        Food: Pizza and Pasta\n",
    "        Currency: Euro\n",
    "        \"\"\",\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"What do you know about Greece?\",\n",
    "        \"answer\": \"\"\"\n",
    "        I know this:\n",
    "        Capital: Athens\n",
    "        Language: Greek\n",
    "        Food: Souvlaki and Feta Cheese\n",
    "        Currency: Euro\n",
    "        \"\"\",\n",
    "    },\n",
    "]\n",
    "\n",
    "class RandomExampleSelector(BaseExampleSelector): \n",
    "\n",
    "  def __init__(self, examples): \n",
    "    self.examples = examples\n",
    "\n",
    "  def add_example(self, example):\n",
    "    self.examples.append(example)\n",
    "\n",
    "  def select_examples(self, input_variables): \n",
    "    from random import choice \n",
    "    return [choice(self.examples)]\n",
    "\n",
    "\n",
    "example_prompt = PromptTemplate.from_template(\"Human: {question}\\nAI: {answer}\")\n",
    "\n",
    "example_selector = RandomExampleSelector(\n",
    "  examples=examples, \n",
    ")\n",
    "\n",
    "prompt = FewShotPromptTemplate(\n",
    "  example_prompt = example_prompt, \n",
    "  example_selector=example_selector,\n",
    "  suffix=\"Human: What do you know about {country}?\", \n",
    "  input_variables=[\"country\"]\n",
    "\n",
    ")\n",
    "\n",
    "prompt.format(country=\"Brazil\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'What is the capital of Germany'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.chat_models import ChatOpenAI \n",
    "from langchain.callbacks import StreamingStdOutCallbackHandler \n",
    "from langchain.prompts import load_prompt\n",
    "\n",
    "\n",
    "prompt = load_prompt(\"./prompt.yaml\")\n",
    "\n",
    "chat = ChatOpenAI(\n",
    "    temperature=0.1,\n",
    "    streaming=True,\n",
    "    callbacks=[\n",
    "        StreamingStdOutCallbackHandler(),\n",
    "    ],\n",
    ")\n",
    "\n",
    "prompt.format(country=\"Germany\") \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import ChatOpenAI \n",
    "from langchain.callbacks import StreamingStdOutCallbackHandler \n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.prompts.pipeline import PipelinePromptTemplate\n",
    "\n",
    "chat = ChatOpenAI(\n",
    "    temperature=0.1,\n",
    "    streaming=True,\n",
    "    callbacks=[\n",
    "        StreamingStdOutCallbackHandler(),\n",
    "    ],\n",
    ")\n",
    "\n",
    "intro = PromptTemplate.from_template(\n",
    "    \"\"\"\n",
    "    You are a role playing assistant.\n",
    "    And you are impersonating a {character}\n",
    "\"\"\"\n",
    ")\n",
    "\n",
    "example = PromptTemplate.from_template(\n",
    "    \"\"\"\n",
    "    This is an example of how you talk:\n",
    "\n",
    "    Human: {example_question}\n",
    "    You: {example_answer}\n",
    "\"\"\"\n",
    ")\n",
    "\n",
    "start = PromptTemplate.from_template(\n",
    "    \"\"\"\n",
    "    Start now!\n",
    "\n",
    "    Human: {question}\n",
    "    You:\n",
    "\"\"\"\n",
    ")\n",
    "\n",
    "final = PromptTemplate.from_template(\n",
    "    \"\"\"\n",
    "    {intro}\n",
    "                                     \n",
    "    {example}\n",
    "                              \n",
    "    {start}\n",
    "\"\"\"\n",
    ")\n",
    "\n",
    "prompts = [\n",
    "  (\"intro\", intro), \n",
    "  (\"example\", example), \n",
    "  (\"start\", start)\n",
    "]\n",
    "\n",
    "\n",
    "full_prompt = PipelinePromptTemplate(\n",
    "    final_prompt=final,\n",
    "    pipeline_prompts=prompts,\n",
    ")\n",
    "\n",
    "\n",
    "chain = full_prompt | chat\n",
    "\n",
    "chain.invoke(\n",
    "    {\n",
    "        \"character\": \"Pirate\",\n",
    "        \"example_question\": \"What is your location?\",\n",
    "        \"example_answer\": \"Arrrrg! That is a secret!! Arg arg!!\",\n",
    "        \"question\": \"What is your fav food?\",\n",
    "    }\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import ChatOpenAI \n",
    "from langchain.callbacks import StreamingStdOutCallbackHandler \n",
    "from langchain.globals import set_llm_cache \n",
    "from langchain.cache import InMemoryCache, SQLiteCache\n",
    "\n",
    "\n",
    "set_llm_cache(SQLiteCache(\"cache.db\")) \n",
    "\n",
    "\n",
    "chat = ChatOpenAI(\n",
    "    temperature=0.1,\n",
    "    # streaming=True,\n",
    "    # callbacks=[\n",
    "    #     StreamingStdOutCallbackHandler(),\n",
    "    # ],\n",
    ")\n",
    "\n",
    "chat.predict(\"How do you make italian pasta\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import ChatOpenAI \n",
    "from langchain.callbacks import get_openai_callback \n",
    "\n",
    "chat = ChatOpenAI( \n",
    "  temperature=0.1\n",
    ")\n",
    "\n",
    "with get_openai_callback() as usage: \n",
    "  a = chat.predict(\"What is the recipe for soju\")\n",
    "  b = chat.predict(\"what is the recipt for bread\")\n",
    "  print(a, b, \"\\n\")\n",
    "  print(usage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import ChatOpenAI \n",
    "from langchain.llms.openai import OpenAI \n",
    "from langchain.llms.loading import load_llm\n",
    "\n",
    "chat = OpenAI(\n",
    "  temperature=0.1, \n",
    "  max_tokens=450, \n",
    "  model=\"gpt-3.5-turbo-16k\"\n",
    ")\n",
    "\n",
    "chat.save(\"model.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import ChatOpenAI \n",
    "from langchain.llms.openai import OpenAI \n",
    "from langchain.llms.loading import load_llm\n",
    "\n",
    "chat = load_llm(\"model.json\")\n",
    "\n",
    "chat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# moel/io Challenge \n",
    "* 영화 이름을 가지고 감독, 주요 출연진, 예산, 흥행 수익, 영화의 장르, 간단한 시놉시스 등 영화에 대한 정보로 답장하는 체인을 만드세요.\n",
    "* LLM은 항상 동일한 형식을 사용하여 응답해야 하며, 이를 위해서는 원하는 출력의 예시를 LLM에 제공해야 합니다.\n",
    "* 예제를 제공하려면 FewShotPromptTemplate 또는 FewShotChatMessagePromptTemplate을 사용하세요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'messages'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[27], line 63\u001b[0m\n\u001b[1;32m     56\u001b[0m example_selector \u001b[38;5;241m=\u001b[39m LengthBasedExampleSelector(\n\u001b[1;32m     57\u001b[0m     examples\u001b[38;5;241m=\u001b[39mexamples,\n\u001b[1;32m     58\u001b[0m     example_prompt\u001b[38;5;241m=\u001b[39mexample_prompt,\n\u001b[1;32m     59\u001b[0m     max_length\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m200\u001b[39m  \u001b[38;5;66;03m# 합리적인 길이로 설정\u001b[39;00m\n\u001b[1;32m     60\u001b[0m )\n\u001b[1;32m     62\u001b[0m \u001b[38;5;66;03m# ChatPromptTemplate 설정\u001b[39;00m\n\u001b[0;32m---> 63\u001b[0m prompt \u001b[38;5;241m=\u001b[39m \u001b[43mChatPromptTemplate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     64\u001b[0m \u001b[43m    \u001b[49m\u001b[43mexample_prompt\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexample_prompt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     65\u001b[0m \u001b[43m    \u001b[49m\u001b[43mexample_selector\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexample_selector\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     66\u001b[0m \u001b[43m    \u001b[49m\u001b[43msuffix\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mHuman: \u001b[39;49m\u001b[38;5;132;43;01m{movie}\u001b[39;49;00m\u001b[38;5;124;43m 영화에 대한 기본 정보를 알려줘?\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     67\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_variables\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmovie\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[1;32m     68\u001b[0m \u001b[43m)\u001b[49m\n\u001b[1;32m     70\u001b[0m \u001b[38;5;66;03m# 프롬프트 포맷\u001b[39;00m\n\u001b[1;32m     71\u001b[0m formatted_prompt \u001b[38;5;241m=\u001b[39m prompt\u001b[38;5;241m.\u001b[39mformat(movie\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m서울의 봄\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/Documents/code/python/nomad/env/lib/python3.11/site-packages/langchain/load/serializable.py:97\u001b[0m, in \u001b[0;36mSerializable.__init__\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m     96\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m---> 97\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     98\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lc_kwargs \u001b[38;5;241m=\u001b[39m kwargs\n",
      "File \u001b[0;32m~/Documents/code/python/nomad/env/lib/python3.11/site-packages/pydantic/main.py:339\u001b[0m, in \u001b[0;36mpydantic.main.BaseModel.__init__\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/Documents/code/python/nomad/env/lib/python3.11/site-packages/pydantic/main.py:1050\u001b[0m, in \u001b[0;36mpydantic.main.validate_model\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/Documents/code/python/nomad/env/lib/python3.11/site-packages/langchain/prompts/chat.py:426\u001b[0m, in \u001b[0;36mChatPromptTemplate.validate_input_variables\u001b[0;34m(cls, values)\u001b[0m\n\u001b[1;32m    413\u001b[0m \u001b[38;5;129m@root_validator\u001b[39m(pre\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m    414\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mvalidate_input_variables\u001b[39m(\u001b[38;5;28mcls\u001b[39m, values: \u001b[38;5;28mdict\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mdict\u001b[39m:\n\u001b[1;32m    415\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Validate input variables.\u001b[39;00m\n\u001b[1;32m    416\u001b[0m \n\u001b[1;32m    417\u001b[0m \u001b[38;5;124;03m    If input_variables is not set, it will be set to the union of\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    424\u001b[0m \u001b[38;5;124;03m        Validated values.\u001b[39;00m\n\u001b[1;32m    425\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 426\u001b[0m     messages \u001b[38;5;241m=\u001b[39m \u001b[43mvalues\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmessages\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[1;32m    427\u001b[0m     input_vars \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n\u001b[1;32m    428\u001b[0m     input_types: Dict[\u001b[38;5;28mstr\u001b[39m, Any] \u001b[38;5;241m=\u001b[39m values\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minput_types\u001b[39m\u001b[38;5;124m\"\u001b[39m, {})\n",
      "\u001b[0;31mKeyError\u001b[0m: 'messages'"
     ]
    }
   ],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.prompts import PromptTemplate, ChatPromptTemplate\n",
    "from langchain.callbacks import StreamingStdOutCallbackHandler\n",
    "from langchain.prompts.example_selector import LengthBasedExampleSelector\n",
    "\n",
    "# Chat 모델 초기화\n",
    "chat = ChatOpenAI(\n",
    "    temperature=0.1,\n",
    "    streaming=True,\n",
    "    callbacks=[\n",
    "        StreamingStdOutCallbackHandler(),\n",
    "    ],\n",
    ")\n",
    "\n",
    "# 예시 정의\n",
    "examples = [\n",
    "    {\n",
    "        \"question\": \"'파묘' 영화에 대한 기본 정보를 알려줘?\",\n",
    "        \"answer\": \"\"\"\n",
    "        영화 제목: 파묘 (The Exhumation)\n",
    "        감독: 김상호\n",
    "        주요 출연진: 박성웅, 이정은, 김혜수, 류준열\n",
    "        예산: 약 500만 달러\n",
    "        흥행 수익: 약 2,000만 달러\n",
    "        장르: 공포, 미스터리, 스릴러\n",
    "        시놉시스: 작은 시골 마을에서 오랜 시간 동안 묻혀 있던 묘지가 강제적으로 파헤쳐지며 기이한 사건들이 일어나기 시작합니다. 오래된 전설에 따르면, 이 묘지에는 마을의 어두운 비밀이 숨겨져 있다고 전해지며, 파묘 작업 이후 마을 사람들은 설명할 수 없는 공포와 미스터리에 휩싸이게 됩니다. 주인공은 이 사건의 진실을 밝히기 위해 고군분투하며, 마을의 숨겨진 과거와 얽힌 진실을 파헤쳐 나갑니다.\n",
    "        \"\"\",\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"'변호인' 영화에 대한 기본 정보를 알려줘?\",\n",
    "        \"answer\": \"\"\"\n",
    "        감독: 양우석\n",
    "        주요 출연진: 송강호, 김영애, 오달수, 곽도원, 임시완\n",
    "        예산: 약 55억 원\n",
    "        흥행 수익: 약 1,100억 원 (한국에서 1,130만 명 이상의 관객을 동원)\n",
    "        장르: 드라마, 법정\n",
    "        시놉시스: 1980년대 초 부산을 배경으로, 송우석 변호사는 세금 전문 변호사로 성공을 거두고 부를 쌓고 있습니다. 그러나 그의 대학 동창의 아들이 국가보안법 위반 혐의로 체포되고 고문당하는 사건을 접하게 됩니다. 송우석은 이를 계기로 인권 변호사로서의 길을 걷게 되고, 불의에 맞서 싸우며 정의를 수호하려 합니다. 이 영화는 실존 인물인 노무현 전 대통령의 초창기 변호사 시절을 모티브로 하여 제작되었습니다.\n",
    "        \"\"\",\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"'극한직업' 영화에 대한 기본 정보를 알려줘?\",\n",
    "        \"answer\": \"\"\"\n",
    "        주요 출연진: 류승룡, 이하늬, 진선규, 이동휘, 공명\n",
    "        예산: 약 65억 원\n",
    "        흥행 수익: 약 1,500억 원 (한국에서 1,626만 명 이상의 관객을 동원하며 역대 흥행 2위 기록)\n",
    "        장르: 코미디, 범죄\n",
    "        시놉시스: 마약반 형사들은 범죄 조직을 소탕하기 위해 잠복 근무를 시작하며 치킨집을 위장 창업하게 됩니다. 그런데 이 치킨집이 의외로 큰 인기를 끌게 되면서 형사들은 본업인 수사와 치킨집 운영 사이에서 갈등하게 됩니다. 코미디와 액션이 어우러진 이 영화는 웃음을 주는 동시에 예기치 못한 상황에서의 긴장감을 제공합니다.\n",
    "        \"\"\",\n",
    "    },\n",
    "]\n",
    "\n",
    "# PromptTemplate 생성\n",
    "example_prompt = PromptTemplate.from_template(\"Human: {question}\\nAI: {answer}\")\n",
    "\n",
    "# ExampleSelector 설정\n",
    "example_selector = LengthBasedExampleSelector(\n",
    "    examples=examples,\n",
    "    example_prompt=example_prompt,\n",
    "    max_length=200  # 합리적인 길이로 설정\n",
    ")\n",
    "\n",
    "# ChatPromptTemplate 설정\n",
    "prompt = ChatPromptTemplate(\n",
    "    example_prompt=example_prompt,\n",
    "    example_selector=example_selector,\n",
    "    suffix=\"Human: {movie} 영화에 대한 기본 정보를 알려줘?\",\n",
    "    input_variables=[\"movie\"]\n",
    ")\n",
    "\n",
    "# 프롬프트 포맷\n",
    "formatted_prompt = prompt.format(movie=\"서울의 봄\")\n",
    "print(formatted_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Marvel is a popular American entertainment company known for its comic books, movies, and TV shows featuring superheroes. Some of the most famous Marvel characters include Spider-Man, Iron Man, Captain America, Thor, Black Widow, and the Hulk. Marvel Studios produces the Marvel Cinematic Universe (MCU), a series of interconnected superhero films that have been highly successful at the box office."
     ]
    },
    {
     "data": {
      "text/plain": [
       "AIMessageChunk(content='Marvel is a popular American entertainment company known for its comic books, movies, and TV shows featuring superheroes. Some of the most famous Marvel characters include Spider-Man, Iron Man, Captain America, Thor, Black Widow, and the Hulk. Marvel Studios produces the Marvel Cinematic Universe (MCU), a series of interconnected superhero films that have been highly successful at the box office.')"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.prompts.few_shot import FewShotChatMessagePromptTemplate\n",
    "from langchain.callbacks import StreamingStdOutCallbackHandler\n",
    "from langchain.prompts import ChatMessagePromptTemplate, ChatPromptTemplate\n",
    "from langchain.prompts.example_selector import LengthBasedExampleSelector\n",
    "\n",
    "chat = ChatOpenAI(\n",
    "    temperature=0.1,\n",
    "    streaming=True,\n",
    "    callbacks=[\n",
    "        StreamingStdOutCallbackHandler(),\n",
    "    ],\n",
    ")\n",
    "\n",
    "examples = [\n",
    "    {\n",
    "        \"movie\": \"파묘\",\n",
    "        \"answer\": \"\"\"\n",
    "        영화 제목: 파묘 (The Exhumation)\n",
    "        감독: 김상호\n",
    "        주요 출연진: 박성웅, 이정은, 김혜수, 류준열\n",
    "        예산: 약 500만 달러\n",
    "        흥행 수익: 약 2,000만 달러\n",
    "        장르: 공포, 미스터리, 스릴러\n",
    "        시놉시스: 작은 시골 마을에서 오랜 시간 동안 묻혀 있던 묘지가 강제적으로 파헤쳐지며 기이한 사건들이 일어나기 시작합니다. 오래된 전설에 따르면, 이 묘지에는 마을의 어두운 비밀이 숨겨져 있다고 전해지며, 파묘 작업 이후 마을 사람들은 설명할 수 없는 공포와 미스터리에 휩싸이게 됩니다. 주인공은 이 사건의 진실을 밝히기 위해 고군분투하며, 마을의 숨겨진 과거와 얽힌 진실을 파헤쳐 나갑니다.\n",
    "        \"\"\",\n",
    "    },\n",
    "    {\n",
    "        \"movie\": \"변호인\",\n",
    "        \"answer\": \"\"\"\n",
    "        감독: 양우석\n",
    "        주요 출연진: 송강호, 김영애, 오달수, 곽도원, 임시완\n",
    "        예산: 약 55억 원\n",
    "        흥행 수익: 약 1,100억 원 (한국에서 1,130만 명 이상의 관객을 동원)\n",
    "        장르: 드라마, 법정\n",
    "        시놉시스: 1980년대 초 부산을 배경으로, 송우석 변호사는 세금 전문 변호사로 성공을 거두고 부를 쌓고 있습니다. 그러나 그의 대학 동창의 아들이 국가보안법 위반 혐의로 체포되고 고문당하는 사건을 접하게 됩니다. 송우석은 이를 계기로 인권 변호사로서의 길을 걷게 되고, 불의에 맞서 싸우며 정의를 수호하려 합니다. 이 영화는 실존 인물인 노무현 전 대통령의 초창기 변호사 시절을 모티브로 하여 제작되었습니다.\n",
    "        \"\"\",\n",
    "    },\n",
    "    {\n",
    "        \"movie\": \"극한직업\",\n",
    "        \"answer\": \"\"\"\n",
    "        주요 출연진: 류승룡, 이하늬, 진선규, 이동휘, 공명\n",
    "        예산: 약 65억 원\n",
    "        흥행 수익: 약 1,500억 원 (한국에서 1,626만 명 이상의 관객을 동원하며 역대 흥행 2위 기록)\n",
    "        장르: 코미디, 범죄\n",
    "        시놉시스: 마약반 형사들은 범죄 조직을 소탕하기 위해 잠복 근무를 시작하며 치킨집을 위장 창업하게 됩니다. 그런데 이 치킨집이 의외로 큰 인기를 끌게 되면서 형사들은 본업인 수사와 치킨집 운영 사이에서 갈등하게 됩니다. 코미디와 액션이 어우러진 이 영화는 웃음을 주는 동시에 예기치 못한 상황에서의 긴장감을 제공합니다.\n",
    "        \"\"\",\n",
    "    },\n",
    "]\n",
    "\n",
    "example_prompt = ChatPromptTemplate.from_messages([\n",
    "  (\"human\", \"{movie} 영화에 대한 기본 정보를 알려줘?\"), \n",
    "  (\"ai\", \"{answer}\")\n",
    "])\n",
    "\n",
    "example_prompt = FewShotChatMessagePromptTemplate(\n",
    "  example_prompt=example_prompt, \n",
    "  examples=examples, \n",
    ")\n",
    "\n",
    "final_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", \"You are a movie expert, you give short answers.\"),\n",
    "        example_prompt,\n",
    "        (\"human\", \"what do you know about {movie}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "chain = final_prompt | chat\n",
    "\n",
    "chain.invoke({\"movie\": \"marvel\"})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
